"""
AI-powered photo analysis and listing generation using OpenAI GPT-4 Vision
Analyzes clothing photos and generates: title, description, price, category, condition, color
"""
import os
import base64
from typing import List, Dict, Any, Optional
from pathlib import Path
import json
import tempfile
from PIL import Image
import pillow_heif

# the newest OpenAI model is "gpt-4o"
from openai import OpenAI
from backend.settings import settings

# Use user's personal OpenAI API key from settings
openai_client = OpenAI(
    api_key=settings.OPENAI_API_KEY,
    timeout=60.0,  # 60 second timeout for API calls
    max_retries=2  # Retry failed requests twice
)
print(f"[OK] OpenAI client initialized (timeout=60s, retries=2, key={'configured' if settings.OPENAI_API_KEY else 'MISSING'})")

# Register HEIF opener with PIL
pillow_heif.register_heif_opener()


def convert_heic_to_jpeg(heic_path: str) -> str:
    """
    Convert HEIC/HEIF image to JPEG format for OpenAI compatibility
    
    Args:
        heic_path: Path to HEIC/HEIF file
        
    Returns:
        Path to converted JPEG file (temp file)
    """
    try:
        # Open HEIC image
        image = Image.open(heic_path)
        
        # Convert to RGB if needed
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        # Create temp JPEG file
        temp_jpeg = tempfile.NamedTemporaryFile(suffix='.jpg', delete=False)
        jpeg_path = temp_jpeg.name
        
        # Save as JPEG
        image.save(jpeg_path, 'JPEG', quality=90)
        
        print(f"[OK] Converted HEIC -> JPEG: {Path(heic_path).name}")
        return jpeg_path
        
    except Exception as e:
        print(f"[ERROR] HEIC conversion error for {heic_path}: {e}")
        # Return original path as fallback
        return heic_path


def encode_image_to_base64(image_path: str) -> str:
    """Convert local image to base64 string, handles HEIC conversion"""
    # Convert HEIC/HEIF to JPEG if needed
    if image_path.lower().endswith(('.heic', '.heif')):
        image_path = convert_heic_to_jpeg(image_path)
    
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')


def analyze_clothing_photos(photo_paths: List[str]) -> Dict[str, Any]:
    """
    Analyze clothing photos using GPT-4 Vision
    WITH REDIS CACHING + IMAGE OPTIMIZATION

    Args:
        photo_paths: List of local file paths to analyze

    Returns:
        Dictionary with:
        - title: Product title
        - description: Detailed description
        - price: Suggested price in euros
        - category: Clothing category (t-shirt, hoodie, jeans, etc.)
        - condition: Condition assessment (new, very good, good, satisfactory)
        - color: Dominant color
        - brand: Detected brand (if visible)
        - size: Detected size (if visible)
        - confidence: Confidence score (0-1)
    """

    # Import caching and optimization services
    try:
        from backend.services.redis_cache import get_cached_analysis, cache_analysis_result
        from backend.services.image_optimizer import batch_optimize_images
    except ImportError as e:
        print(f"[WARN]  Service import failed: {e}, running without optimization")
        get_cached_analysis = lambda x: None
        cache_analysis_result = lambda x, y: False
        batch_optimize_images = lambda x: x

    try:
        # STEP 1: Check Redis cache first (huge cost savings!)
        cached_result = get_cached_analysis(photo_paths[:6])
        if cached_result:
            print(f"[CACHE HIT] Returning cached analysis [OK]")
            return cached_result

        # STEP 2: Optimize images before API call (75% cost reduction!)
        print(f"[OPTIMIZE] Optimizing {len(photo_paths[:6])} images...")
        optimized_paths = batch_optimize_images(photo_paths[:6])

        # STEP 3: Prepare images for API call
        image_contents = []
        for path in optimized_paths:
            if not Path(path).exists():
                print(f"[WARN] Photo not found: {path}")
                continue

            # Encode image to base64
            base64_image = encode_image_to_base64(path)
            image_contents.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{base64_image}"
                }
            })
        
        if not image_contents:
            raise ValueError("No valid images found")
        
        # VINTED ULTRA-OPTIMIZED PROMPT (2025 Algorithm - Based on Top Sellers Analysis)
        # STRATEGY: Mobile-first, emoji structure, SEO keywords, trust-building, call-to-action
        prompt = """Tu es un EXPERT VINTED avec 10 ans d'exp√©rience et tu connais PARFAITEMENT l'algorithme 2025.

üéØ OBJECTIF : G√©n√©rer titre + description qui EXPLOSENT la visibilit√© gr√¢ce √† :
- Mots-cl√©s ultra-cibl√©s (marque, type, couleur, taille, style, saison)
- Structure mobile-friendly avec emojis (üìåüîçüìè‚ú®üè∑Ô∏è)
- Honn√™tet√© totale sur d√©fauts (build trust = moins de retours)
- Mesures pr√©cises (algorithme Vinted booste √ßa)
- Hashtags strat√©giques int√©gr√©s
- Call-to-action finale

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üìù STRUCTURE OPTIMIS√âE DESCRIPTION VINTED 2025 :

1Ô∏è‚É£ TITRE (40-55 caract√®res MAX) :
   Format : [Marque] [Type] [Couleur] [Taille] [1 mot style/occasion]
   Exemples :
   - "Zara blazer marine M chic bureau"
   - "Nike tech fleece noir L streetwear"
   - "Levi's 501 jean bleu W32 vintage"

2Ô∏è‚É£ DESCRIPTION (Structure avec emojis) :

üìå INFOS ESSENTIELLES
‚Ä¢ Marque : [pr√©cise ou "√† pr√©ciser"]
‚Ä¢ Type : [blazer/hoodie/jean slim/robe midi/etc + synonymes]
‚Ä¢ Taille : [exacte + √©quivalence EU/US si possible]
‚Ä¢ Couleur : [dominante + nuances/motifs]
‚Ä¢ Mati√®re : [composition pr√©cise OU "coton doux" si invisible]
‚Ä¢ Coupe : [slim/oversize/droit/boyfriend/mom/skinny...]

üîç √âTAT & D√âTAILS HONN√äTES
‚Ä¢ √âtat : [Neuf √©tiquette / Excellent (1-2 ports) / Tr√®s bon / Bon / Satisfaisant] + nombre de ports
‚Ä¢ Points forts : [poches/broderie/fermeture √©clair/√©lastique/col/motifs/√©dition limit√©e...]
‚Ä¢ D√©fauts : [TOUJOURS mentionner : boulochage/mini-accroc/couleur pass√©e/traces d'usage OU "Aucun d√©faut visible"]

üìè MESURES PR√âCISES (boost algorithmique !)
‚Ä¢ Longueur : [Xcm]
‚Ä¢ Largeur √©paules/Poitrine : [Xcm]
‚Ä¢ Taille/Hanches : [Xcm si applicable]
‚Ä¢ Entrejambe : [Xcm pour pantalons]

‚ú® STYLE & USAGE INSPIRANT
‚Ä¢ Saison : [automne-hiver/printemps-√©t√©/4 saisons/mi-saison]
‚Ä¢ Style : [casual/chic/sport/streetwear/vintage/boh√®me/minimaliste/Y2K/grunge]
‚Ä¢ Parfait pour : [bureau/soir√©e/quotidien/sport/vacances/festival/date]
‚Ä¢ Conseils look : "S'assemble parfaitement avec [jean mom/baskets blanches/jupe midi...] pour un look [d√©contract√©/pro/tendance] !"

Envoi rapide et soign√© ! üì¶

üè∑Ô∏è HASHTAGS STRAT√âGIQUES (8-12 tags)
[Format : #marque #type #taille #couleur #style #saison #occasion #coupe]
Exemples : #zara #blazer #tailleM #marine #chic #printemps #bureau #coupedroite

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üö® R√àGLES CRITIQUES VINTED 2025 :

‚úÖ √Ä FAIRE ABSOLUMENT :
- Utiliser TOUS les synonymes possibles (blazer = veste tailleur, jean = denim, etc.)
- Mentionner d√©fauts HONN√äTEMENT (trust = conversion)
- Donner mesures PR√âCISES en cm (favoris√© par algo)
- Varier vocabulaire pour SEO (oversize, boyfriend, mom jean, crop top, wide leg...)
- Adapter prix selon marque + raret√© + condition
- Phrase finale engageante type "Envoi rapide !" ou "Dispo de suite !"

‚ùå √Ä √âVITER :
- Phrases vagues : "bon √©tat" sans d√©tails
- "Voir photos" (algo p√©nalise)
- Jargon pro : "pi√®ce incontournable", "qualit√© premium" (trop boutique)
- Titre > 55 caract√®res (coup√© sur mobile)
- Oublier les d√©fauts (retours clients)

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üìä SCH√âMA JSON DE SORTIE (STRICT) :

{
  "title": "string",                    // 40-55 chars MAX
  "description": "string",              // Format emojis üìåüîçüìè‚ú®üè∑Ô∏è
  "brand": "string|null",               // Pr√©cis ou "√† pr√©ciser"
  "category": "string",                 // hoodie/jean/blazer/robe/etc
  "size": "string|null",                // L, M, W32, EU38, "√† v√©rifier"
  "condition": "string",                // Neuf √©tiquette|Excellent|Tr√®s bon|Bon|Satisfaisant
  "color": "string",                    // Pr√©cis : noir/marine/beige/multicolore
  "materials": "string|null",           // Composition OU texture si invisible
  "fit": "string|null",                 // slim/oversize/droit/boyfriend/mom/wide leg
  "style": "string|null",               // casual/chic/streetwear/vintage/Y2K/grunge/boh√®me
  "seasonality": "string|null",         // automne-hiver/printemps-√©t√©/4 saisons
  "defects": "string|null",             // Pr√©cis OU "Aucun d√©faut visible"
  "rarity": "string|null",              // collab/√©dition limit√©e/vintage/null
  "price": number,                      // Justifi√© par marque+raret√©+condition
  "price_justification": "string",      // Ex: "marque premium + excellent √©tat"
  "confidence": number,                 // 0.0-1.0
  "measurements": {                     // NOUVEAU pour boost algo
    "length_cm": number|null,
    "chest_width_cm": number|null,
    "waist_cm": number|null,
    "inseam_cm": number|null
  },
  "hashtags": ["string"],               // 8-12 tags strat√©giques
  "search_keywords": ["string"]         // NOUVEAU : synonymes pour SEO interne
}

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üí° EXEMPLES PARFAITS (TOP SELLERS 2025) :

EXEMPLE 1 - Blazer Zara :
{
  "title": "Zara blazer marine M chic bureau printemps",
  "description": "üìå INFOS ESSENTIELLES\n‚Ä¢ Marque : Zara\n‚Ä¢ Type : Blazer veste tailleur femme\n‚Ä¢ Taille : M (voir mesures)\n‚Ä¢ Couleur : Bleu marine profond uni\n‚Ä¢ Mati√®re : 65% coton, 35% polyester, doublure viscose\n‚Ä¢ Coupe : Droite structur√©e, √©paulettes l√©g√®res\n\nüîç √âTAT & D√âTAILS\n‚Ä¢ √âtat : Excellent (port√© 2 fois)\n‚Ä¢ Points forts : 2 poches plaqu√©es, 4 boutons dor√©s, col crant√©, fente dos\n‚Ä¢ D√©fauts : Aucun d√©faut visible\n\nüìè MESURES PR√âCISES\n‚Ä¢ Longueur : 68cm\n‚Ä¢ Largeur √©paules : 40cm\n‚Ä¢ Tour de poitrine : 92cm\n\n‚ú® STYLE & USAGE\n‚Ä¢ Saison : Printemps-√©t√©, mi-saison\n‚Ä¢ Style : Chic classique, business casual\n‚Ä¢ Parfait pour : Bureau, entretien, soir√©e chic, rendez-vous pro\n‚Ä¢ Conseils : S'assemble avec pantalon cigarette blanc ou jean mom pour un look pro-d√©contract√© !\n\nEnvoi rapide et soign√© ! üì¶\n\nüè∑Ô∏è #zara #blazer #tailleM #marine #chic #bureau #printemps #femme #classique #pro",
  "brand": "Zara",
  "category": "blazer",
  "size": "M",
  "condition": "Excellent",
  "color": "bleu marine",
  "materials": "65% coton, 35% polyester",
  "fit": "droit structur√©",
  "style": "chic classique",
  "seasonality": "printemps-√©t√©",
  "defects": "Aucun d√©faut visible",
  "rarity": null,
  "price": 35,
  "price_justification": "marque tendance + excellent √©tat + pi√®ce intemporelle",
  "confidence": 0.95,
  "measurements": {
    "length_cm": 68,
    "chest_width_cm": 46,
    "waist_cm": null,
    "inseam_cm": null
  },
  "hashtags": ["#zara", "#blazer", "#tailleM", "#marine", "#chic", "#bureau", "#printemps", "#femme", "#classique", "#pro"],
  "search_keywords": ["veste tailleur", "blazer femme", "veste bureau", "zara femme", "blazer marine", "veste chic"]
}

EXEMPLE 2 - Hoodie Streetwear :
{
  "title": "Nike tech fleece noir L streetwear hiver",
  "description": "üìå INFOS ESSENTIELLES\n‚Ä¢ Marque : Nike\n‚Ä¢ Type : Hoodie tech fleece sweat √† capuche\n‚Ä¢ Taille : L (coupe slim)\n‚Ä¢ Couleur : Noir total avec logo blanc\n‚Ä¢ Mati√®re : Tech fleece (polyester doux isolant)\n‚Ä¢ Coupe : Slim fit moderne\n\nüîç √âTAT & D√âTAILS\n‚Ä¢ √âtat : Tr√®s bon (port√© 5-6 fois)\n‚Ä¢ Points forts : Zip int√©gral, 2 poches zipp√©es, capuche ajustable, finitions premium\n‚Ä¢ D√©fauts : L√©ger boulochage aux coudes (quasi invisible)\n\nüìè MESURES PR√âCISES\n‚Ä¢ Longueur : 70cm\n‚Ä¢ Largeur √©paules : 50cm\n‚Ä¢ Tour de poitrine : 106cm\n\n‚ú® STYLE & USAGE\n‚Ä¢ Saison : Automne-hiver (tr√®s chaud)\n‚Ä¢ Style : Streetwear urbain, sportswear premium\n‚Ä¢ Parfait pour : Quotidien, sport, sorties, look street\n‚Ä¢ Conseils : Nickel avec jogging ou jean slim et sneakers blanches pour un style propre !\n\nDispo de suite ! üì¶\n\nüè∑Ô∏è #nike #techfleece #hoodie #noir #streetwear #L #hiver #sport #urbain #premium",
  "brand": "Nike",
  "category": "hoodie",
  "size": "L",
  "condition": "Tr√®s bon √©tat",
  "color": "noir",
  "materials": "polyester tech fleece",
  "fit": "slim fit",
  "style": "streetwear",
  "seasonality": "automne-hiver",
  "defects": "l√©ger boulochage aux coudes",
  "rarity": null,
  "price": 65,
  "price_justification": "marque premium + tech fleece recherch√© + tr√®s bon √©tat",
  "confidence": 0.92,
  "measurements": {
    "length_cm": 70,
    "chest_width_cm": 53,
    "waist_cm": null,
    "inseam_cm": null
  },
  "hashtags": ["#nike", "#techfleece", "#hoodie", "#noir", "#streetwear", "#L", "#hiver", "#sport", "#urbain", "#premium"],
  "search_keywords": ["sweat nike", "hoodie noir", "tech fleece", "nike sportswear", "sweat capuche", "streetwear hiver"]
}

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üî¨ ANALYSE VISUELLE CRITIQUE :

1. **Marque** : Cherche √©tiquette, logo, broderie ‚Üí Si invisible : "√† pr√©ciser sur √©tiquette"
2. **Type exact** : Hoodie/sweat/pull/t-shirt/chemise/blazer/jean/jogging/short/robe/jupe...
3. **Taille** : √âtiquette visible ? ‚Üí Sinon : "√† v√©rifier" + donner mesures
4. **Couleur** : Pr√©cis (marine ‚â† bleu roi, beige ‚â† √©cru, noir ‚â† anthracite)
5. **Mati√®re** : Texture visible ? (coton/polyester/denim/laine/synth√©tique)
6. **D√©fauts** : SCRUTE CHAQUE PIXEL ‚Üí taches, bouloches, coutures, trous, d√©coloration, √©lasticit√©
7. **Style** : Esth√©tique (streetwear/Y2K/vintage/casual/chic/sport/grunge/preppy/boh√®me)
8. **Raret√©** : Collab (Nike x Off-White), √©dition limit√©e, vintage authentique, pi√®ce unique
9. **Saison** : √âpaisseur tissu ‚Üí hiver (√©pais) / √©t√© (l√©ger) / 4 saisons (moyen)
10. **Mesures** : Estime en cm depuis rep√®res visuels (col-bas, √©paule-√©paule...)
11. **Prix** : Justifi√© par marque + raret√© + condition + demande
12. **Hashtags** : Mots-cl√©s TENDANCE (#oversized #vintage #y2k #rare #collector #90s #2000s)

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Analyse maintenant les photos et g√©n√®re le JSON EXACT selon ce format. Sois ULTRA-PR√âCIS."""

        # Build messages
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    *image_contents
                ]
            }
        ]
        
        print(f"[SEARCH] Analyzing {len(image_contents)} photos with GPT-4 Vision...")
        
        # Call OpenAI API with increased tokens for richer descriptions
        response = openai_client.chat.completions.create(
            model="gpt-4o",  # Use GPT-4 with vision capabilities
            messages=messages,  # type: ignore
            max_tokens=1500,  # Increased for detailed Vinted-optimized descriptions
            temperature=0.7,
            response_format={"type": "json_object"}
        )
        
        # Parse JSON response
        content = response.choices[0].message.content or "{}"
        result = json.loads(content)

        print(f"[SUCCESS] Analysis complete: {result.get('title', 'Unknown')}")
        print(f"   Category: {result.get('category')}, Price: {result.get('price')}‚Ç¨")

        # STEP 4: Cache the result for future use (30 day TTL)
        cache_analysis_result(photo_paths[:6], result)

        # STEP 5: Track quality metrics
        try:
            from backend.services.redis_cache import track_ai_quality_metrics
            is_valid, errors = validate_ai_result(result)
            track_ai_quality_metrics(result, is_valid)
        except Exception as e:
            print(f"[WARN]  Metrics tracking failed: {e}")

        return result

    except json.JSONDecodeError as e:
        print(f"[ERROR] JSON parse error: {e}")
        # Return fallback result
        fallback = generate_fallback_analysis(photo_paths)

        # Track fallback usage
        try:
            from backend.services.redis_cache import track_ai_quality_metrics
            track_ai_quality_metrics(fallback, False)
        except:
            pass

        return fallback

    except Exception as e:
        print(f"[ERROR] AI analysis error: {e}")
        # Return fallback result
        fallback = generate_fallback_analysis(photo_paths)

        # Track fallback usage
        try:
            from backend.services.redis_cache import track_ai_quality_metrics
            track_ai_quality_metrics(fallback, False)
        except:
            pass

        return fallback


def validate_ai_result(result: Dict[str, Any]) -> tuple[bool, List[str]]:
    """
    Validate AI-generated listing against quality gates
    
    Returns:
        (is_valid, list_of_errors)
    """
    errors = []
    
    # Check title length
    title = result.get("title", "")
    if len(title) > 70:
        errors.append(f"Title too long ({len(title)} chars, max 70)")
    
    # Check for emojis in title/description
    import re
    emoji_pattern = re.compile("["
        u"\U0001F600-\U0001F64F"  # emoticons
        u"\U0001F300-\U0001F5FF"  # symbols & pictographs
        u"\U0001F680-\U0001F6FF"  # transport & map symbols
        u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
        u"\U00002702-\U000027B0"
        u"\U000024C2-\U0001F251"
        "]+", flags=re.UNICODE)
    
    if emoji_pattern.search(title):
        errors.append("Title contains emojis (forbidden)")
    
    description = result.get("description", "")
    if emoji_pattern.search(description):
        errors.append("Description contains emojis (forbidden)")
    
    # Check hashtags (should be 3-5, at end of description)
    hashtag_count = description.count("#")
    if hashtag_count < 3 or hashtag_count > 5:
        errors.append(f"Invalid hashtag count ({hashtag_count}, need 3-5)")
    
    # Check mandatory fields
    if not result.get("condition"):
        errors.append("Missing 'condition' field")
    if not result.get("size"):
        errors.append("Missing 'size' field")
    
    # Check for forbidden marketing phrases
    forbidden_phrases = ["parfait pour", "style tendance", "casual chic", "d√©couvrez", "id√©al"]
    for phrase in forbidden_phrases:
        if phrase.lower() in description.lower():
            errors.append(f"Forbidden marketing phrase: '{phrase}'")
    
    return (len(errors) == 0, errors)


def generate_fallback_analysis(photo_paths: List[str]) -> Dict[str, Any]:
    """
    Generate a basic fallback analysis when AI fails
    Uses simple heuristics - MUST comply with strict quality gates
    Ensures condition and size are ALWAYS filled (never null/empty)
    """
    return {
        "title": "V√™tement √† identifier ‚Äì bon √©tat",
        "description": "Article en bon √©tat visible sur photos. Mati√®re et d√©tails √† pr√©ciser selon photos fournies. Taille √† v√©rifier. Envoi rapide. Remise possible si achat group√©. #mode #vinted #occasion",
        "price": 20,
        "category": "autre",
        "condition": "Bon √©tat",  # MANDATORY: Default value if AI fails
        "color": "Non sp√©cifi√©",
        "brand": "Non sp√©cifi√©",
        "size": "Taille non visible",  # MANDATORY: Default value if AI fails (changed from "Non sp√©cifi√©")
        "confidence": 0.3,
        "fallback": True
    }


def batch_analyze_photos(photo_groups: List[List[str]]) -> List[Dict[str, Any]]:
    """
    Analyze multiple groups of photos (for bulk upload)
    Each group represents one clothing item
    
    Args:
        photo_groups: List of photo path lists, e.g. [[photo1, photo2], [photo3, photo4]]
        
    Returns:
        List of analysis results (one per group)
    """
    results = []
    
    for i, group in enumerate(photo_groups):
        print(f"\n[PHOTO] Analyzing group {i+1}/{len(photo_groups)} ({len(group)} photos)...")
        try:
            result = analyze_clothing_photos(group)
            result['group_index'] = i
            result['photos'] = group  # CRITICAL: Attach photos to result for draft creation
            results.append(result)
        except Exception as e:
            print(f"[ERROR] Group {i+1} failed: {e}")
            fallback = generate_fallback_analysis(group)
            fallback['group_index'] = i
            fallback['photos'] = group  # CRITICAL: Attach photos to fallback result
            results.append(fallback)
    
    return results


def smart_group_photos(photo_paths: List[str], max_per_group: int = 7) -> List[List[str]]:
    """
    Intelligently group photos into clothing items using image metadata
    Uses aspect ratio, file size, and color similarity for better grouping
    
    Args:
        photo_paths: All photo paths
        max_per_group: Maximum photos per item (default 7 minimum)
        
    Returns:
        List of photo groups
    """
    import imagehash
    from PIL import Image
    
    # Extract metadata for each photo
    photo_metadata = []
    for path in photo_paths:
        try:
            img = Image.open(path)
            aspect_ratio = img.width / img.height if img.height > 0 else 1.0
            file_size = Path(path).stat().st_size
            # Use pHash for perceptual similarity
            phash = imagehash.phash(img)
            photo_metadata.append({
                'path': path,
                'aspect_ratio': aspect_ratio,
                'file_size': file_size,
                'phash': phash
            })
        except Exception as e:
            print(f"[WARN] Metadata extraction failed for {path}: {e}")
            # Fallback metadata
            photo_metadata.append({
                'path': path,
                'aspect_ratio': 1.0,
                'file_size': 0,
                'phash': None
            })
    
    # Group photos by similarity
    groups = []
    used_indices = set()
    
    for i, meta in enumerate(photo_metadata):
        if i in used_indices:
            continue
            
        # Start new group with current photo
        current_group = [meta['path']]
        used_indices.add(i)
        
        # Find similar photos for this group
        for j, other_meta in enumerate(photo_metadata[i+1:], start=i+1):
            if j in used_indices or len(current_group) >= max_per_group:
                continue
            
            # Check similarity
            is_similar = False
            
            # Similar aspect ratio (within 15%)
            aspect_diff = abs(meta['aspect_ratio'] - other_meta['aspect_ratio'])
            if aspect_diff < 0.15:
                is_similar = True
            
            # Similar file size (within 50% for same photo session)
            if meta['file_size'] > 0 and other_meta['file_size'] > 0:
                size_ratio = min(meta['file_size'], other_meta['file_size']) / max(meta['file_size'], other_meta['file_size'])
                if size_ratio > 0.5:
                    is_similar = True
            
            # Perceptual hash similarity (Hamming distance < 10)
            if meta['phash'] and other_meta['phash']:
                hash_distance = meta['phash'] - other_meta['phash']
                if hash_distance < 10:
                    is_similar = True
            
            if is_similar:
                current_group.append(other_meta['path'])
                used_indices.add(j)
        
        groups.append(current_group)
    
    print(f"[PACKAGE] Smart grouped {len(photo_paths)} photos into {len(groups)} items (similarity-based)")
    return groups


def smart_analyze_and_group_photos(
    photo_paths: List[str], 
    style: str = "classique"
) -> List[Dict[str, Any]]:
    """
    INTELLIGENT GROUPING WITH AUTO-BATCHING: Analyze ALL photos by chunks and let AI group them
    
    If >25 photos: splits into batches of 25, analyzes each, returns all items
    If ‚â§25 photos: analyzes all together
    
    Args:
        photo_paths: All photo paths to analyze (no limit!)
        style: "minimal", "streetwear", or "classique" (default)
        
    Returns:
        List of analyzed items with their grouped photos
    """
    total_photos = len(photo_paths)
    BATCH_SIZE = 25  # Safe batch size to stay under 30k token limit
    
    # If ‚â§25 photos, analyze all together
    if total_photos <= BATCH_SIZE:
        return _analyze_single_batch(photo_paths, style)
    
    # If >25 photos, split into batches and analyze each
    print(f"[PACKAGE] Auto-batching: {total_photos} photos -> splitting into batches of {BATCH_SIZE}")
    
    all_items = []
    offset = 0
    batch_num = 1
    total_batches = (total_photos + BATCH_SIZE - 1) // BATCH_SIZE
    
    while offset < total_photos:
        batch_photos = photo_paths[offset:offset + BATCH_SIZE]
        print(f"\n[BATCH] Batch {batch_num}/{total_batches}: Analyzing photos {offset+1}-{offset+len(batch_photos)}...")
        
        try:
            batch_items = _analyze_single_batch(batch_photos, style, offset)
            all_items.extend(batch_items)
            print(f"[OK] Batch {batch_num} complete: {len(batch_items)} items detected")
        except Exception as e:
            print(f"[ERROR] Batch {batch_num} failed: {e}, using fallback")
            # Fallback: group batch photos by 7 photos per item
            fallback_groups = smart_group_photos(batch_photos, max_per_group=7)
            fallback_items = batch_analyze_photos(fallback_groups)
            all_items.extend(fallback_items)
        
        offset += BATCH_SIZE
        batch_num += 1
    
    print(f"\n[OK] Auto-batching complete: {len(all_items)} total items from {total_photos} photos")
    return all_items


def _normalize_size_field(size: str) -> str:
    """
    [FIX] NORMALISATION TAILLE - Extrait UNIQUEMENT la taille adulte finale
    
    Exemples:
    - "16Y / 165 cm (‚âà XS)" -> "XS"
    - "XS (‚âà 16Y)" -> "XS"  
    - "12 ans (‚âà S)" -> "S"
    - "M" -> "M"
    
    Returns:
        Taille adulte simple (XS/S/M/L/XL/XXL) ou fallback
    """
    import re
    
    if not size or size.strip() == "":
        return "M"  # Fallback par d√©faut
    
    # Si d√©j√† une taille simple adulte, retourner directement
    size_upper = size.strip().upper()
    simple_sizes = ["XXS", "XS", "S", "M", "L", "XL", "XXL", "XXXL"]
    if size_upper in simple_sizes:
        return size_upper
    
    # Extraire la taille adulte de formats complexes (ex: "16Y / 165 cm (‚âà XS)")
    # Chercher pattern: (‚âà TAILLE) ou / TAILLE) ou juste TAILLE
    match = re.search(r'[‚âà\(]\s*([X]{0,3}[SMLX]{1,3})\s*[\)]', size.upper())
    if match:
        extracted = match.group(1)
        if extracted in simple_sizes:
            return extracted
    
    # Chercher directement une taille dans la cha√Æne
    for sz in simple_sizes:
        if re.search(rf'\b{sz}\b', size.upper()):
            return sz
    
    # Si "Taille non visible" ou √©quivalent
    if "non visible" in size.lower() or "non sp√©cifi√©" in size.lower():
        return "Taille non visible"
    
    # Fallback
    return "M"


def _normalize_condition_field(condition: str) -> str:
    """
    [FIX] NORMALISATION CONDITION - Convertit en fran√ßais standardis√©
    
    Returns:
        Condition en fran√ßais (Vinted-compatible)
    """
    if not condition:
        return "Bon √©tat"
    
    condition_lower = condition.lower().strip()
    
    # Mapping anglais -> fran√ßais
    if condition_lower in ["new with tags", "neuf avec √©tiquette", "neuf avec √©tiquettes"]:
        return "Neuf avec √©tiquette"
    elif condition_lower in ["new", "neuf", "neuf sans √©tiquette"]:
        return "Neuf sans √©tiquette"
    elif condition_lower in ["very good", "tr√®s bon √©tat", "tr√®s bon"]:
        return "Tr√®s bon √©tat"
    elif condition_lower in ["good", "bon √©tat", "bon"]:
        return "Bon √©tat"
    elif condition_lower in ["satisfactory", "satisfaisant", "√©tat satisfaisant"]:
        return "Satisfaisant"
    
    # Fallback
    return "Bon √©tat"


def _auto_polish_draft(draft: Dict[str, Any]) -> Dict[str, Any]:
    """
    [FIX] POLISSAGE AUTOMATIQUE 100% - Garantit que le brouillon est PARFAIT
    
    Corrections automatiques :
    - Supprime TOUS les emojis
    - Supprime TOUTES les phrases marketing
    - Force TOUS les champs obligatoires
    - Corrige les hashtags (3-5, √† la fin)
    - Ajuste le prix si n√©cessaire
    - Raccourcit le titre si trop long
    - NORMALISE la taille (XS au lieu de "16Y / 165 cm (‚âà XS)")
    - NORMALISE la condition en fran√ßais
    
    Returns:
        Draft corrig√© et 100% pr√™t √† publier
    """
    import re
    
    # 1. NETTOYER EMOJIS (title + description)
    emoji_pattern = re.compile("["
        u"\U0001F600-\U0001F64F"  # emoticons
        u"\U0001F300-\U0001F5FF"  # symbols & pictographs
        u"\U0001F680-\U0001F6FF"  # transport & map symbols
        u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
        u"\U00002702-\U000027B0"
        u"\U000024C2-\U0001F251"
        "]+", flags=re.UNICODE)
    
    title = draft.get("title", "")
    description = draft.get("description", "")
    
    original_title = title
    original_description = description
    
    title = emoji_pattern.sub("", title).strip()
    description = emoji_pattern.sub("", description).strip()
    
    if title != original_title or description != original_description:
        print(f"[CLEAN] Emojis supprim√©s automatiquement")
    
    # 2. NETTOYER PHRASES MARKETING
    forbidden_phrases = [
        "parfait pour", "id√©al pour", "style tendance", "casual chic", 
        "d√©couvrez", "magnifique", "prestigieuse", "haute qualit√©",
        "look", "tendance", "must-have", "incontournable"
    ]
    
    description_lower = description.lower()
    for phrase in forbidden_phrases:
        if phrase in description_lower:
            # Supprimer la phrase (simple remplacement)
            description = re.sub(rf'\b{re.escape(phrase)}\b', '', description, flags=re.IGNORECASE)
            description = re.sub(r'\s+', ' ', description).strip()  # Nettoyer espaces
            print(f"[CLEAN] Phrase marketing supprim√©e : '{phrase}'")
    
    # 2.5 VALIDER VOCABULAIRE PAR CAT√âGORIE (CRITIQUE - MATCHING FLEXIBLE)
    category = draft.get("category", "").lower()
    
    # Mapping cat√©gories -> groupes (matching par sous-cha√Æne pour robustesse)
    TOPS_KEYWORDS = ["hoodie", "sweat", "pull", "t-shirt", "tshirt", "tee", "chemise", 
                     "blouse", "veste", "blouson", "manteau", "doudoune", "parka", "cardigan",
                     "top", "d√©bardeur", "gilet"]
    BOTTOMS_KEYWORDS = ["jogging", "pantalon", "jean", "short", "bermuda", "legging", 
                        "surv√™tement", "jogger", "cargo", "chino"]
    
    # D√©tection flexible : cat√©gorie contient-elle un mot-cl√© ?
    is_top = any(keyword in category for keyword in TOPS_KEYWORDS)
    is_bottom = any(keyword in category for keyword in BOTTOMS_KEYWORDS)
    
    # Termes interdits par groupe (avec mapping vers remplacements contextuels)
    if is_bottom:
        # BAS : SUPPRIMER TOTALEMENT vocabulaire HAUTS
        forbidden_replacements = {
            r'\bpoitrine\b': 'cuisse',
            r'\b√©paules?\b': 'taille',
            r'\bmanches?\b': 'jambes',
            r'\bcapuche\b': '',  # Supprimer compl√®tement (illogique pour un bas)
            r'\bcol\b': '',
            r'\bdos\b': '',
            r'\bencolure\b': '',
            r'\bpoignets?\b': 'chevilles',
            r'\bbrod√© poitrine\b': 'brod√© cuisse',
            r'\bimprim√© poitrine\b': 'imprim√© cuisse',
            r'\bd√©tail dos\b': 'd√©tail arri√®re',
            r'\bmanches longues\b': 'jambes longues',
            r'\bmanches courtes\b': 'jambes courtes'
        }
        
        for pattern, replacement in forbidden_replacements.items():
            if re.search(pattern, description_lower):
                match_text = re.search(pattern, description_lower)
                if match_text:
                    print(f"[ALERT] VOCABULAIRE INCORRECT '{match_text.group()}' dans {category} (BAS) -> '{replacement or 'supprim√©'}'")
                if replacement:
                    description = re.sub(pattern, replacement, description, flags=re.IGNORECASE)
                else:
                    # Supprimer le terme + contexte autour
                    description = re.sub(rf'[,\s]*{pattern}[,\s]*', ' ', description, flags=re.IGNORECASE)
                    description = re.sub(r'\s+', ' ', description).strip()
    
    elif is_top:
        # HAUTS : SUPPRIMER TOTALEMENT vocabulaire BAS (EXHAUSTIF)
        forbidden_replacements = {
            r'\bentrejambe\b': '',
            r'\bcuisses?\b': 'manches',
            r'\bchevilles?\b': 'poignets',
            # Tous les contextes "taille" = WAIST (pas SIZE)
            r'\btaille √©lastique\b': 'poignets √©lastiques',
            r'\btaille ajustable\b': 'poignets ajustables',
            r'\btaille r√©glable\b': 'poignets r√©glables',
            r'\btaille resserr√©e\b': 'poignets resserr√©s',
            r'\btaille cintr√©e\b': 'coupe cintr√©e',
            r'\btaille stretch\b': 'tissu stretch',
            r'\bserrage √† la taille\b': 'serrage aux poignets',
            r'\bceinture √† la taille\b': 'bord c√¥tel√©',
            r'\b√† la taille\b': '√† la taille basse',  # Edge case : peut rester si contexte bas de v√™tement
            r'\btour de taille\b': 'tour de poitrine',
            r'\bpoches taille\b': 'poches poitrine',
            # Autres vocabulaire BAS
            r'\bbrod√© cuisse\b': 'brod√© poitrine',
            r'\bimprim√© cuisse\b': 'imprim√© poitrine',
            r'\bjambes longues\b': 'manches longues',
            r'\bjambes courtes\b': 'manches courtes'
        }
        
        for pattern, replacement in forbidden_replacements.items():
            if re.search(pattern, description_lower):
                match_text = re.search(pattern, description_lower)
                if match_text:
                    print(f"[ALERT] VOCABULAIRE INCORRECT '{match_text.group()}' dans {category} (HAUT) -> '{replacement or 'supprim√©'}'")
                if replacement:
                    description = re.sub(pattern, replacement, description, flags=re.IGNORECASE)
                else:
                    # Supprimer le terme
                    description = re.sub(rf'[,\s]*{pattern}[,\s]*', ' ', description, flags=re.IGNORECASE)
                    description = re.sub(r'\s+', ' ', description).strip()
    
    # V√âRIFICATION FINALE : S'assurer qu'AUCUN terme interdit ne subsiste
    if is_bottom:
        # BAS : aucun vocabulaire de HAUTS ne doit survivre
        final_check = [
            r'\bpoitrine\b', r'\b√©paules?\b', r'\bmanches?\b', r'\bcapuche\b', 
            r'\bcol\b', r'\bdos\b', r'\bencolure\b', r'\bpoignets?\b'
        ]
        for pattern in final_check:
            if re.search(pattern, description.lower()):
                # Dernier filet de s√©curit√© : supprimer brutalement
                print(f"[WARN]  ALERTE : terme interdit '{pattern}' d√©tect√© apr√®s corrections -> suppression forc√©e")
                description = re.sub(pattern, '', description, flags=re.IGNORECASE)
                description = re.sub(r'\s+', ' ', description).strip()
    
    elif is_top:
        # HAUTS : aucun vocabulaire de BAS ne doit survivre (EXHAUSTIF : tous les contextes "taille"=WAIST)
        final_check = [
            r'\bentrejambe\b', r'\bcuisses?\b', r'\bchevilles?\b',
            # Tous les usages "taille" = WAIST (pas SIZE)
            r'\btour de taille\b', r'\btaille ajustable\b', r'\btaille √©lastique\b',
            r'\btaille r√©glable\b', r'\btaille resserr√©e\b', r'\btaille cintr√©e\b',
            r'\btaille stretch\b', r'\bserrage √† la taille\b', r'\bceinture √† la taille\b',
            r'\btaille \(waist\)', r'\bpoches taille\b',
            r'\bjambes?\s+(longues?|courtes?)\b'  # "jambes longues" mais pas "jambes" seul
        ]
        for pattern in final_check:
            if re.search(pattern, description.lower()):
                print(f"[WARN]  ALERTE : terme interdit '{pattern}' d√©tect√© apr√®s corrections -> suppression forc√©e")
                description = re.sub(pattern, '', description, flags=re.IGNORECASE)
                description = re.sub(r'\s+', ' ', description).strip()
    
    else:
        # FALLBACK CONSERVATEUR pour cat√©gories non g√©r√©es (robes, jupes, accessoires)
        # -> Appliquer r√®gles TOPS par d√©faut (plus s√ªr que de ne rien faire)
        if category and category not in ["v√™tement", "", "autre"]:
            print(f"[INFO]  Cat√©gorie '{category}' non class√©e -> application des r√®gles TOPS par d√©faut")
            # Supprimer vocabulaire BAS √©vident (entrejambe, cuisses)
            description = re.sub(r'\bentrejambe\b', '', description, flags=re.IGNORECASE)
            description = re.sub(r'\bcuisses?\b', '', description, flags=re.IGNORECASE)
            description = re.sub(r'\s+', ' ', description).strip()
    
    # 3. NORMALISER ET GARANTIR CHAMPS OBLIGATOIRES
    
    # condition (JAMAIS vide + normalisation fran√ßaise)
    original_condition = draft.get("condition", "").strip()
    condition = _normalize_condition_field(original_condition)
    if condition != original_condition:
        print(f"[FIX] Condition normalis√©e : '{original_condition}' -> '{condition}'")
    draft["condition"] = condition
    
    # size (JAMAIS vide + extraction taille adulte simple)
    original_size = draft.get("size", "").strip()
    size = _normalize_size_field(original_size)
    if size != original_size:
        print(f"[FIX] Taille simplifi√©e : '{original_size}' -> '{size}'")
    draft["size"] = size
    
    # brand (fallback si vide)
    brand = draft.get("brand", "").strip()
    if not brand or brand.lower() in ["", "non sp√©cifi√©", "unknown", "n/a"]:
        brand = "Marque non visible"
        draft["brand"] = brand
    
    # color (fallback si vide)
    color = draft.get("color", "").strip()
    if not color or color.lower() in ["", "non sp√©cifi√©", "unknown", "n/a"]:
        color = "Couleur vari√©e"
        draft["color"] = color
    
    # category (fallback si vide)
    category = draft.get("category", "").strip()
    if not category or category.lower() in ["", "non sp√©cifi√©", "unknown", "autre"]:
        category = "v√™tement"
        draft["category"] = category
    
    # 4. CORRIGER HASHTAGS (3-5, √† la fin)
    hashtags = re.findall(r'#\w+', description)
    
    if len(hashtags) < 3:
        print(f"[WARN]  Pas assez de hashtags ({len(hashtags)}), ajout automatique")
        # G√©n√©rer hashtags manquants
        missing_count = 3 - len(hashtags)
        auto_hashtags = []
        
        if brand.lower() not in ["marque non visible", "non sp√©cifi√©"]:
            auto_hashtags.append(f"#{brand.lower().replace(' ', '')}")
        if category and category != "v√™tement":
            auto_hashtags.append(f"#{category.lower().replace(' ', '').replace('-', '')}")
        if color.lower() not in ["couleur vari√©e", "non sp√©cifi√©"]:
            auto_hashtags.append(f"#{color.lower().replace(' ', '')}")
        
        # Ajouter hashtags g√©n√©riques si besoin
        generic_hashtags = ["#mode", "#vinted", "#occasion", "#vetement"]
        auto_hashtags.extend(generic_hashtags[:missing_count])
        
        hashtags.extend(auto_hashtags[:missing_count])
    
    if len(hashtags) > 5:
        print(f"[WARN]  Trop de hashtags ({len(hashtags)}), r√©duction √† 5")
        hashtags = hashtags[:5]
    
    # Supprimer hashtags de la description, puis les remettre √† la fin
    description_no_hashtags = re.sub(r'#\w+', '', description).strip()
    description_no_hashtags = re.sub(r'\s+', ' ', description_no_hashtags).strip()
    
    # Ajouter les hashtags √† la fin
    hashtag_string = " ".join(hashtags)
    description = f"{description_no_hashtags} {hashtag_string}".strip()
    
    # 5. RACCOURCIR TITRE SI TROP LONG (‚â§70 chars)
    if len(title) > 70:
        print(f"[WARN]  Titre trop long ({len(title)} chars), r√©duction √† 70")
        # Garder d√©but + √©tat
        title = title[:67] + "..."
    
    # 6. AJUSTER PRIX AVEC LE MARCH√â VINTED R√âEL
    original_price = draft.get("price", 20)
    try:
        # Utiliser le pricing bas√© sur le march√© r√©el
        import asyncio
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

        adjusted_price = loop.run_until_complete(_get_market_price(draft))
    except Exception as e:
        print(f"[PRICE] Erreur market pricing: {e}, utilisation fallback")
        adjusted_price = _adjust_price_if_needed(draft)

    if adjusted_price != original_price:
        print(f"[PRICE] Prix ajust√© : {original_price}‚Ç¨ -> {adjusted_price}‚Ç¨")
        draft["price"] = adjusted_price
    
    # 7. METTRE √Ä JOUR LE DRAFT
    draft["title"] = title
    draft["description"] = description
    
    return draft


async def _get_market_price(item: Dict[str, Any]) -> float:
    """
    Obtenir le prix bas√© sur le march√© r√©el Vinted (SCRAPING)
    Scrape les prix d'articles similaires pour donner un prix pr√©cis

    Args:
        item: Dict avec title, brand, category, condition, size

    Returns:
        Prix bas√© sur le march√© r√©el en euros
    """
    try:
        from backend.core.market_pricing_engine import MarketPricingEngine
        from backend.core.session import SessionVault
        from backend.settings import settings

        # Charger la session Vinted
        vault = SessionVault(
            key=settings.SECRET_KEY,
            storage_path=settings.SESSION_STORE_PATH
        )
        session = vault.load_session()

        if not session:
            print("[PRICING] No Vinted session available, using fallback")
            return _adjust_price_if_needed(item)

        # Utiliser le moteur de pricing intelligent
        engine = MarketPricingEngine(session)

        recommendation = await engine.get_price_recommendation(
            title=item.get("title", ""),
            category=item.get("category", ""),
            brand=item.get("brand"),
            condition=item.get("condition", "Bon √©tat"),
            size=item.get("size"),
            photos_quality_score=75.0  # Score moyen
        )

        print(f"[PRICING] Market price: {recommendation.recommended_price}‚Ç¨ (confidence: {recommendation.confidence:.0%})")
        return recommendation.recommended_price

    except Exception as e:
        print(f"[PRICING] Market pricing failed: {e}, using fallback")
        return _adjust_price_if_needed(item)


def _adjust_price_if_needed(item: Dict[str, Any]) -> float:
    """
    FALLBACK: Ajuster le prix avec multiplicateurs si le scraping √©choue

    Args:
        item: Dict avec brand, category, condition, price

    Returns:
        Prix ajust√© en euros
    """
    category = (item.get("category") or "").lower()
    brand = (item.get("brand") or "").lower()
    condition = (item.get("condition") or "Bon √©tat").lower()
    
    # BASES CAT√âGORIES (prix de d√©part r√©alistes)
    base_prices = {
        "t-shirt": 18, "polo": 18, "top": 18,
        "chemise": 20, "blouse": 20,
        "pull": 25, "sweat": 25, "cardigan": 25,
        "hoodie": 38, "sweatshirt": 38,
        "pantalon": 32, "jean": 32, "jeans": 32,
        "short": 25, "bermuda": 25,
        "jogging": 28, "surv√™tement": 28,
        "veste": 55, "blouson": 55,
        "manteau": 60, "coat": 60,
        "doudoune": 70, "parka": 70
    }
    
    # Trouver la cat√©gorie
    base_price = 20  # Default
    for cat_key, price in base_prices.items():
        if cat_key in category:
            base_price = price
            break
    
    # MULTIPLICATEURS MARQUE
    brand_multiplier = 1.0
    
    # Luxe (√ó3.0 √† √ó5.0)
    luxury_brands = ["burberry", "dior", "gucci", "louis vuitton", "lv", "prada", "chanel", "herm√®s", "hermes", "yves saint laurent", "ysl"]
    if any(b in brand for b in luxury_brands):
        brand_multiplier = 3.5
    
    # Premium (√ó2.0 √† √ó2.5) - FIX CRITIQUE : Karl Lagerfeld, Ralph Lauren, etc.
    elif any(b in brand for b in ["ralph lauren", "polo", "karl lagerfeld", "diesel", "tommy hilfiger", "lacoste", "hugo boss", "calvin klein"]):
        brand_multiplier = 2.2
    
    # Streetwear (√ó2.5 √† √ó3.5)
    elif any(b in brand for b in ["fear of god", "essentials", "supreme", "off-white", "bape", "a bathing ape"]):
        brand_multiplier = 2.8
    
    # Sportswear premium (√ó2.0 √† √ó2.8)
    elif any(b in brand for b in ["yeezy", "jordan", "off white"]):
        brand_multiplier = 2.5
    
    # Standard (√ó1.0) - Zara, H&M, Uniqlo
    elif any(b in brand for b in ["zara", "h&m", "uniqlo", "mango", "asos"]):
        brand_multiplier = 1.0
    
    # Entr√©e de gamme (√ó0.8)
    elif "non sp√©cifi√©" in brand or not brand:
        brand_multiplier = 0.8
    
    # MULTIPLICATEURS CONDITION
    condition_multiplier = 0.70  # "Bon √©tat" par d√©faut
    if "neuf avec" in condition:
        condition_multiplier = 1.00
    elif "neuf" in condition:
        condition_multiplier = 0.95
    elif "tr√®s bon" in condition:
        condition_multiplier = 0.85
    elif "bon" in condition:
        condition_multiplier = 0.70
    elif "satisfaisant" in condition:
        condition_multiplier = 0.55
    
    # CALCUL
    calculated_price = base_price * brand_multiplier * condition_multiplier
    
    # ARRONDIS PSYCHOLOGIQUES
    if calculated_price < 40:
        # Arrondir √† 9, 19, 29, 39
        adjusted = round(calculated_price / 10) * 10 - 1
        if adjusted < 9:
            adjusted = 9
    elif calculated_price < 100:
        # Arrondir √† 49, 59, 69, 79, 89, 99
        adjusted = round(calculated_price / 10) * 10 - 1
    else:
        # Arrondir √† 99, 119, 129, 149, 199
        adjusted = round(calculated_price / 10) * 10 - 1
    
    return int(adjusted)


def _analyze_single_batch(
    photo_paths: List[str],
    style: str = "classique",
    photo_offset: int = 0
) -> List[Dict[str, Any]]:
    """
    Internal: Analyze a single batch of photos (‚â§25 photos)
    
    Args:
        photo_paths: Photos to analyze (max 25)
        style: Description style
        photo_offset: Offset for photo indices (used in batching)
        
    Returns:
        List of analyzed items
    """
    try:
        # Prepare images for API call
        image_contents = []
        valid_paths = []
        
        for path in photo_paths:  # Already limited to BATCH_SIZE
            if not Path(path).exists():
                print(f"[WARN] Photo not found: {path}")
                continue
                
            # Encode image to base64
            base64_image = encode_image_to_base64(path)
            image_contents.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{base64_image}"
                }
            })
            valid_paths.append(path)
        
        if not image_contents:
            raise ValueError("No valid images found")
        
        # Create intelligent grouping prompt with natural casual tone
        prompt = f"""Tu vends tes v√™tements sur Vinted. Tu re√ßois {len(image_contents)} photos et tu dois les GROUPER intelligemment par pi√®ce/v√™tement, puis √©crire des descriptions naturelles pour chaque groupe. √âcris comme une vraie personne, pas comme une boutique pro.

R√àGLES DE GROUPEMENT CRITIQUES (anti-saucisson ET anti-m√©lange):
1. **UNE PI√àCE = UN ARTICLE** : Regrouper TOUTES les photos d'une m√™me pi√®ce/v√™tement dans un seul article pour maximiser la visualisation acheteur.

2. **PLUSIEURS PI√àCES = PLUSIEURS GROUPES S√âPAR√âS** (R√àGLE ABSOLUE):
   Tu DOIS cr√©er des groupes s√©par√©s si tu d√©tectes :
   ‚Ä¢ Marques DIFF√âRENTES (ex: Burberry ‚â† Ralph Lauren -> 2 groupes)
   ‚Ä¢ Couleurs DIFF√âRENTES (ex: t-shirt noir ‚â† t-shirt blanc -> 2 groupes)  
   ‚Ä¢ Coupes/styles DIFF√âRENTS (ex: hoodie ‚â† t-shirt -> 2 groupes)
   ‚Ä¢ Logos/motifs DIFF√âRENTS (ex: logo Lacoste ‚â† logo Polo -> 2 groupes)
   ‚Ä¢ Tailles adultes DIFF√âRENTES (ex: XS ‚â† M -> 2 groupes)
   
   [RULE] INTERDIT ABSOLU : M√©langer des v√™tements diff√©rents dans le m√™me groupe (ex: t-shirt noir + t-shirt blanc = ERREUR GRAVE)

3. **JAMAIS de listing multi-pi√®ces** : Interdiction absolue de cr√©er "lot de 2 t-shirts" ou combiner plusieurs v√™tements dans un article.

4. **D√©tecter les d√©tails** : Les photos de d√©tails/√©tiquettes/macros (‚â§2 photos isol√©es) doivent √™tre fusionn√©es avec le groupe principal du m√™me v√™tement.

5. Les √©tiquettes (care labels, brand tags, size labels) DOIVENT √™tre rattach√©es au v√™tement principal correspondant - JAMAIS cr√©er d'article "√©tiquette seule".

6. **TOUTES LES PHOTOS D'UN M√äME V√äTEMENT ENSEMBLE** : Pour un m√™me v√™tement/pi√®ce, tu DOIS regrouper TOUTES ses photos dans UN SEUL article (pas de limite maximum). Par exemple, si 6 photos montrent le m√™me hoodie sous diff√©rents angles, cr√©e UN SEUL article avec les 6 photos. NE PAS diviser les photos d'un m√™me v√™tement en plusieurs articles.

CHAMPS OBLIGATOIRES (NE JAMAIS LAISSER VIDE):

**condition** (OBLIGATOIRE - JAMAIS NULL/VIDE):
  [WARN] CE CHAMP NE DOIT JAMAIS √äTRE null, undefined, ou vide [WARN]
  D√©terminer l'√©tat selon les photos. TOUJOURS remplir ce champ.
  Valeurs autoris√©es UNIQUEMENT:
  ‚Ä¢ "Neuf avec √©tiquette" : √©tiquette visible sur la photo
  ‚Ä¢ "Neuf sans √©tiquette" : article impeccable, jamais port√©
  ‚Ä¢ "Tr√®s bon √©tat" : l√©g√®res traces d'usage, propre
  ‚Ä¢ "Bon √©tat" : usure visible mais bon √©tat g√©n√©ral
  ‚Ä¢ "Satisfaisant" : d√©fauts visibles (t√¢ches, trous, d√©coloration)
  
  [RULE] R√àGLE ABSOLUE : Si tu ne vois pas assez de d√©tails pour d√©terminer l'√©tat pr√©cis, tu DOIS choisir "Bon √©tat" par d√©faut.
  [RULE] INTERDIT ABSOLU : Retourner null, undefined, "", ou omettre ce champ. Le JSON sera REJET√â.

**size** (OBLIGATOIRE - JAMAIS NULL/VIDE):
  [WARN] CE CHAMP NE DOIT JAMAIS √äTRE null, undefined, ou vide [WARN]
  [WARN] RETOURNER UNIQUEMENT LA TAILLE ADULTE NORMALIS√âE (XS/S/M/L/XL/XXL) [WARN]
  
  [RULE] R√àGLES CRITIQUES - LIS EXACTEMENT L'√âTIQUETTE (PRIORIT√â ABSOLUE):
  
  1Ô∏è‚É£ Si l'√©tiquette montre UNE TAILLE ADULTE (XS, S, M, L, XL, XXL) :
     -> Retourne CETTE taille directement : "L", "M", "XS", etc.
     -> PAS de conversion, PAS d'√©quivalence
     -> Exemple : √©tiquette dit "L" -> size: "L" (JAMAIS "XS" !)
  
  2Ô∏è‚É£ Si l'√©tiquette montre UNIQUEMENT une taille enfant (16Y, 14 ans, 165cm) :
     -> Estime la taille adulte PRUDEMMENT (16Y peut √™tre S, M ou L selon marque!)
     -> Exemple : "16Y" seul -> size: "M" (estimation moyenne prudente)
     -> ATTENTION : NE PAS supposer automatiquement que 16Y = XS !
  
  3Ô∏è‚É£ Si l'√©tiquette montre LES DEUX (ex: "16Y / L" ou "165cm / M") :
     -> PRIVIL√âGIE TOUJOURS la taille adulte : size: "L"
     -> Ignore la taille enfant dans le champ size
  
  4Ô∏è‚É£ Si AUCUNE taille visible sur les photos :
     -> size: "Taille non visible"
  
  ESTIMATIONS PRUDENTES (si UNIQUEMENT taille enfant visible):
  ‚Ä¢ 14Y / 152-158cm -> "S" ou "XS" (prudent: "S")
  ‚Ä¢ 16Y / 165cm -> "M" ou "L" (prudent: "M") [WARN] PAS automatiquement "XS" !
  ‚Ä¢ 18Y / 170-176cm -> "L" ou "M" (prudent: "L")
  ‚Ä¢ Si doute -> "M" (taille moyenne par d√©faut)
  
  FORMAT √Ä RESPECTER ABSOLUMENT:
  [OK] BON : "L" (si √©tiquette montre "L")
  [OK] BON : "M" (si √©tiquette montre "M" ou estimation 16Y)
  [OK] BON : "XS" (si √©tiquette montre "XS")
  [ERROR] MAUVAIS : "16Y / 165 cm (‚âà XS)" (NE JAMAIS inclure taille d'origine)
  [ERROR] MAUVAIS : "XS (‚âà 16Y)" (PAS de parenth√®ses ni √©quivalences)
  [ERROR] MAUVAIS : "XS" si l'√©tiquette montre "L" (ERREUR GRAVE !)
  
  [RULE] R√àGLE ABSOLUE : Si aucune taille n'est visible -> retourner "Taille non visible" (texte exact)
  [RULE] INTERDIT ABSOLU : Retourner null, undefined, "", ou omettre ce champ. Le JSON sera REJET√â.

LISTING POUR CHAQUE GROUPE:

title (‚â§70 chars, format SIMPLE ¬´ {{Cat√©gorie}} {{Couleur}} {{Marque?}} {{Taille}} ‚Äì {{√âtat}} ¬ª)
  [WARN] FORMAT SIMPLIFI√â - PAS de parenth√®ses, PAS d'√©quivalences, PAS de mesures
  
  Exemples CORRECTS:
  [OK] "T-shirt noir Burberry XS ‚Äì tr√®s bon √©tat"
  [OK] "Jogging noir Burberry XS ‚Äì bon √©tat"
  [OK] "Hoodie Karl Lagerfeld noir M ‚Äì tr√®s bon √©tat"
  
  Exemples INTERDITS:
  [ERROR] "T-shirt noir Burberry XS (‚âà 16Y/165 cm) ‚Äì tr√®s bon √©tat" (PAS de parenth√®ses)
  [ERROR] "Jogging Burberry 16Y / 165 cm ‚Äì bon √©tat" (utiliser taille adulte)
  
  INTERDITS: emojis, superlatifs ("magnifique", "parfait"), marketing ("d√©couvrez", "id√©al pour"), parenth√®ses avec √©quivalences

description (4‚Äì6 lignes max, ton naturel et d√©contract√©, Z√âRO emoji, Z√âRO phrases commerciales)
  Parle comme une vraie personne qui vend ses v√™tements :
  - "Je vends mon...", "Port√© quelques fois", "Super √©tat", "Nickel", "Impec"
  - Mentionne l'essentiel : ce que c'est, √©tat honn√™te, taille, style
  - D√©fauts simplement : "quelques traces", "l√©ger boulochage", "rien de grave"
  - Pas de d√©tails techniques compliqu√©s (composition exacte, etc.)
  - √âvite les phrases commerciales : "qualit√© assur√©e", "pi√®ce incontournable", "style tendance"

  Exemple TON NATUREL: "Je vends mon hoodie Karl Lagerfeld noir et blanc. Port√© quelques fois, super √©tat, juste un l√©ger boulochage aux coudes mais rien de m√©chant. Style streetwear cool. Taille L, nickel pour l'automne-hiver. Dispo de suite !"

  MENTIONNE HONN√äTEMENT:
  ‚Ä¢ D√©fauts de fa√ßon simple et directe (pas de langue de bois)
  ‚Ä¢ √âtat g√©n√©ral sans exag√©rer
  ‚Ä¢ Taille et style basique
  ‚Ä¢ Si vintage/rare, dis-le simplement

  INTERDITS: emojis, marketing ("parfait pour", "style tendance", "pi√®ce magnifique", "qualit√© assur√©e"), superlatifs excessifs, d√©tails techniques inutiles

hashtags (3‚Äì5 SIMPLES et naturels, √Ä LA FIN de la description)
  Hashtags basiques et directs, pas trop compliqu√©s
  Exemple: #karllagerfeld #hoodie #streetwear #noir
  Ou: #burberry #jogging #vintage #y2k

price (sugg√©r√© en euros, bases r√©alistes Vinted 2025)
  BASES CAT√âGORIES:
  - T-shirt/polo: 18‚Ç¨ | Chemise: 20‚Ç¨ | Pull/sweat: 25‚Ç¨ | Hoodie: 38‚Ç¨
  - Pantalon/jean: 32‚Ç¨ | Short: 25‚Ç¨ | Jogging: 28‚Ç¨
  - Veste l√©g√®re: 55‚Ç¨ | Manteau: 60‚Ç¨ | Doudoune: 70‚Ç¨
  
  MULTIPLICATEURS MARQUE (tr√®s important pour premium):
  - Luxe (Burberry, Dior, Gucci, LV, Prada): √ó3.0 √† √ó5.0
  - **Premium (Ralph Lauren, Karl Lagerfeld, Diesel, Tommy Hilfiger, Lacoste, Hugo Boss): √ó2.0 √† √ó2.5**
  - Streetwear (Fear of God Essentials, Supreme, Off-White): √ó2.5 √† √ó3.5
  - Sportswear premium (Adidas Yeezy, Nike Jordan): √ó2.0 √† √ó2.8
  - Standard (Zara, H&M, Uniqlo, marques connues): √ó1.0
  - Entr√©e de gamme (no-name, basique): √ó0.8
  
  MULTIPLICATEURS CONDITION:
  - Neuf avec √©tiquettes: √ó1.00
  - Tr√®s bon √©tat: √ó0.85
  - Bon √©tat: √ó0.70
  - Satisfaisant: √ó0.55
  
  ARRONDIS PSYCHOLOGIQUES:
  - <40‚Ç¨ -> finit par 9 (ex: 19‚Ç¨, 29‚Ç¨, 39‚Ç¨)
  - 40‚Äì99‚Ç¨ -> 49/59/69/79/89/99‚Ç¨
  - ‚â•100‚Ç¨ -> 99/119/129/149/199‚Ç¨
  
  EXEMPLES CONCRETS:
  - Short Ralph Lauren bon √©tat: 25‚Ç¨ √ó 2.0 √ó 0.70 = 35‚Ç¨ -> 39‚Ç¨
  - Hoodie Karl Lagerfeld tr√®s bon: 38‚Ç¨ √ó 2.2 √ó 0.85 = 71‚Ç¨ -> 69‚Ç¨
  - T-shirt Burberry satisfaisant: 18‚Ç¨ √ó 3.5 √ó 0.55 = 35‚Ç¨ -> 39‚Ç¨
  - Veste Essentials bon √©tat: 55‚Ç¨ √ó 2.8 √ó 0.70 = 108‚Ç¨ -> 99‚Ç¨

STYLE (adapte selon "{style}"):
- minimal: Ton sobre, descriptions factuelles courtes
- streetwear: Ton lifestyle direct, sans emojis ni marketing
- classique: Ton boutique sobre, descriptions soign√©es

QUALITY GATE (CRIT√àRES SANS-√âCHEC):
- title.length ‚â§70
- 3 ‚â§ hashtags.length ‚â§5
- AUCUN emoji dans title/description
- AUCUN superlatif ("magnifique", "prestigieuse", "haute qualit√©", "parfait pour", "tendance", "id√©al")
- AUCUNE phrase marketing ("parfait pour", "style tendance", "casual chic", "look", "d√©couvrez")
- **condition doit √™tre rempli (valeur par d√©faut: "Bon √©tat" si impossible √† d√©terminer)**
- **size doit √™tre rempli (valeur par d√©faut: "Taille non visible" si impossible √† lire)**
- Hashtags UNIQUEMENT √† la fin de la description

INTERDITS ABSOLUS: emojis, marketing creux ("d√©couvrez", "parfait pour", "style tendance", slogans), liens/contacts, promesses hors plateforme, "authentique/original" sans preuve.

TON NATUREL OBLIGATOIRE : √âcris comme une vraie personne qui vend ses v√™tements, pas comme une boutique. Utilise "Je vends mon...", "Port√© quelques fois", "Super √©tat", "Nickel". Description 4-6 lignes max : 1) ce que c'est, 2) √©tat honn√™te avec d√©fauts si besoin, 3) taille et style, 4) envoi. Pas de marketing, pas de phrases creuses.

SORTIE JSON OBLIGATOIRE (TON NATUREL):
{{
  "groups": [
    {{
      "title": "T-shirt Burberry noir XS vintage",
      "description": "Je vends mon t-shirt Burberry noir des ann√©es 2000. Port√© plusieurs fois, bon √©tat g√©n√©ral. Le col a tr√®s l√©g√®rement d√©color√© mais rien de grave. Style Y2K sympa. Taille XS. Envoi rapide. #burberry #tshirt #vintage #y2k #noir",
      "price": 59,
      "brand": "Burberry",
      "size": "XS",
      "condition": "Bon √©tat",
      "color": "Noir",
      "category": "t-shirt",
      "style": "vintage Y2K",
      "seasonality": "toutes saisons",
      "defects": "tr√®s l√©g√®re d√©coloration col",
      "rarity": "vintage ann√©es 2000",
      "price_justification": "marque luxe + vintage",
      "confidence": 0.90,
      "photo_indices": [0, 1]
    }}
  ]
}}

Analyse les photos et g√©n√®re le JSON:"""

        # Build messages
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    *image_contents
                ]
            }
        ]
        
        print(f"[AI] Analyzing {len(image_contents)} photos with GPT-4 Vision...")
        
        # Call OpenAI API with intelligent grouping
        response = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=messages,  # type: ignore
            max_tokens=3000,  # More tokens for multiple items
            temperature=0.7,
            response_format={"type": "json_object"}
        )
        
        # Parse JSON response
        content = response.choices[0].message.content or "{}"
        result = json.loads(content)
        
        # Map photo indices to actual paths (adjust for batch offset)
        groups = result.get("groups", [])
        validated_groups = []
        
        for group in groups:
            indices = group.pop("photo_indices", [])
            group["photos"] = [valid_paths[i] for i in indices if i < len(valid_paths)]
            
            # [FIX] POLISSAGE AUTOMATIQUE 100% (Garantit brouillons parfaits)
            group = _auto_polish_draft(group)
            
            # [OK] VALIDATION FINALE (apr√®s polissage)
            validation_errors = []
            
            # 1. V√©rifier nombre minimum de photos (‚â•3 photos obligatoire)
            photo_count = len(group.get("photos", []))
            if photo_count < 3:
                validation_errors.append(f"Trop peu de photos ({photo_count}, minimum 3)")
            
            # 2. V√©rifier title ‚â§70 chars
            title = group.get("title", "")
            if len(title) > 70:
                validation_errors.append(f"Titre trop long ({len(title)} chars, max 70)")
            
            # 3. V√©rifier hashtags 3-5
            description = group.get("description", "")
            hashtag_count = description.count("#")
            if hashtag_count < 3 or hashtag_count > 5:
                validation_errors.append(f"Hashtags invalides ({hashtag_count}, besoin 3-5)")
            
            # Si validation √©choue apr√®s polissage, REJETER
            if validation_errors:
                print(f"[ERROR] Article REJET√â (apr√®s polissage) : {title[:50]}")
                for error in validation_errors:
                    print(f"   ‚Ä¢ {error}")
                continue  # Skip this article
            
            validated_groups.append(group)
        
        print(f"\n{'='*80}")
        print(f"[OK] VALIDATION FINALE : {len(validated_groups)}/{len(groups)} articles valid√©s")
        print(f"{'='*80}")
        for i, group in enumerate(validated_groups, 1):
            title = group.get('title', 'N/A')
            photo_count = len(group.get('photos', []))
            condition = group.get('condition', 'N/A')
            price = group.get('price', 0)
            brand = group.get('brand', 'N/A')
            size = group.get('size', 'N/A')
            
            print(f"[{i}] {title}")
            print(f"    [PHOTO] Photos: {photo_count} | [PRICE] Prix: {price}‚Ç¨ | [LABEL]  Marque: {brand}")
            print(f"    [EMOJI] √âtat: {condition} | [SIZE] Taille: {size}")
        
        return validated_groups
        
    except Exception as e:
        print(f"[ERROR] Batch analysis error: {e}")
        raise  # Let the caller handle the fallback
