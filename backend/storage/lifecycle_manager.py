"""
Storage Lifecycle Manager
DÃ©place automatiquement les photos entre tiers selon leur utilisation
ExÃ©cutÃ© quotidiennement via cron job
"""
from datetime import datetime, timedelta
from typing import List
from loguru import logger

from .storage_manager import StorageManager, StorageTier, PhotoMetadata


class StorageLifecycleManager:
    """
    GÃ¨re le cycle de vie des photos

    RÃ¨gles:
    1. TEMP > 48h â†’ Suppression OU promotion HOT
    2. Photos publiÃ©es > 7j â†’ Suppression
    3. TEMP non publiÃ© > 48h â†’ HOT
    4. HOT sans accÃ¨s 90j â†’ COLD
    5. COLD > 365j â†’ Suppression

    ExÃ©cutÃ©: Quotidiennement Ã  3h du matin (cron job)
    """

    def __init__(self, storage_manager: StorageManager):
        """
        Initialize lifecycle manager

        Args:
            storage_manager: StorageManager instance
        """
        self.storage = storage_manager

    async def run_daily_lifecycle(self):
        """
        Job quotidien de lifecycle

        Actions:
        1. Supprimer photos TEMP > 48h
        2. Supprimer photos publiÃ©es > 7j
        3. Promouvoir TEMP â†’ HOT si draft reste
        4. Archiver HOT â†’ COLD si 90j sans accÃ¨s
        5. Supprimer COLD > 365j
        """
        logger.info("ðŸ”„ Starting storage lifecycle job")

        now = datetime.utcnow()

        # Stats
        stats = {
            'temp_deleted': 0,
            'published_deleted': 0,
            'promoted_to_hot': 0,
            'archived_to_cold': 0,
            'old_deleted': 0
        }

        # 1. Supprimer photos TEMP expirÃ©es
        logger.info("ðŸ“‹ Step 1: Deleting expired TEMP photos")
        temp_photos = await self._get_photos_by_tier(StorageTier.TEMP)

        for photo in temp_photos:
            if photo.scheduled_deletion and photo.scheduled_deletion < now:
                logger.info(f"ðŸ—‘ï¸ Deleting expired TEMP photo: {photo.photo_id}")
                await self.storage.delete_photo(photo.photo_id)
                stats['temp_deleted'] += 1

        # 2. Supprimer photos publiÃ©es expirÃ©es (7j aprÃ¨s publication)
        logger.info("ðŸ“‹ Step 2: Deleting published photos (7+ days)")
        published_photos = await self._get_published_photos()

        for photo in published_photos:
            if photo.scheduled_deletion and photo.scheduled_deletion < now:
                logger.info(
                    f"ðŸ—‘ï¸ Deleting published photo: {photo.photo_id} "
                    f"(published {(now - photo.published_date).days} days ago)"
                )
                await self.storage.delete_photo(photo.photo_id)
                stats['published_deleted'] += 1

        # 3. Promouvoir TEMP â†’ HOT (drafts non publiÃ©s)
        logger.info("ðŸ“‹ Step 3: Promoting TEMP â†’ HOT (non-published drafts)")
        temp_old = await self._get_photos_older_than(
            StorageTier.TEMP,
            hours=48
        )

        for photo in temp_old:
            if not photo.published_to_vinted:
                logger.info(
                    f"â¬†ï¸ Promoting to HOT storage: {photo.photo_id} "
                    f"(draft_id: {photo.draft_id})"
                )
                await self.storage.promote_to_hot_storage(photo.photo_id)
                stats['promoted_to_hot'] += 1

        # 4. Archiver HOT â†’ COLD (90j sans accÃ¨s)
        logger.info("ðŸ“‹ Step 4: Archiving HOT â†’ COLD (90+ days without access)")
        hot_old = await self._get_photos_not_accessed_for(
            StorageTier.HOT,
            days=90
        )

        for photo in hot_old:
            logger.info(
                f"ðŸ“¦ Archiving to COLD storage: {photo.photo_id} "
                f"(last accessed {(now - photo.last_accessed).days} days ago)"
            )
            await self.storage.archive_to_cold_storage(photo.photo_id)
            stats['archived_to_cold'] += 1

        # 5. Supprimer COLD > 365j
        logger.info("ðŸ“‹ Step 5: Deleting old COLD photos (365+ days)")
        cold_old = await self._get_photos_older_than(
            StorageTier.COLD,
            days=365
        )

        for photo in cold_old:
            logger.info(
                f"ðŸ—‘ï¸ Deleting old COLD photo: {photo.photo_id} "
                f"(uploaded {(now - photo.upload_date).days} days ago)"
            )
            await self.storage.delete_photo(photo.photo_id)
            stats['old_deleted'] += 1

        # Log summary
        logger.info(
            f"âœ… Storage lifecycle job completed\n"
            f"   - TEMP deleted: {stats['temp_deleted']}\n"
            f"   - Published deleted: {stats['published_deleted']}\n"
            f"   - Promoted to HOT: {stats['promoted_to_hot']}\n"
            f"   - Archived to COLD: {stats['archived_to_cold']}\n"
            f"   - Old photos deleted: {stats['old_deleted']}"
        )

        return stats

    async def _get_photos_by_tier(self, tier: StorageTier) -> List[PhotoMetadata]:
        """
        RÃ©cupÃ¨re toutes les photos d'un tier

        Args:
            tier: Tier de stockage

        Returns:
            Liste de PhotoMetadata
        """
        from backend.core.storage import get_store

        store = get_store()
        with store.get_connection() as conn:
            cursor = conn.cursor()

            cursor.execute("""
                SELECT * FROM photo_metadata WHERE tier = ?
            """, (tier.value,))

            rows = cursor.fetchall()

            photos = []
            for row in rows:
                photo = PhotoMetadata(
                    photo_id=row['photo_id'],
                    user_id=row['user_id'],
                    draft_id=row['draft_id'],
                    tier=StorageTier(row['tier']),
                    original_filename=row['original_filename'],
                    size_bytes=row['size_bytes'],
                    compressed_size_bytes=row['compressed_size_bytes'],
                    upload_date=datetime.fromisoformat(row['upload_date']) if row['upload_date'] else None,
                    last_accessed=datetime.fromisoformat(row['last_accessed']) if row['last_accessed'] else None,
                    published_to_vinted=bool(row['published_to_vinted']),
                    published_date=datetime.fromisoformat(row['published_date']) if row['published_date'] else None,
                    scheduled_deletion=datetime.fromisoformat(row['scheduled_deletion']) if row['scheduled_deletion'] else None
                )
                photos.append(photo)

            return photos

    async def _get_published_photos(self) -> List[PhotoMetadata]:
        """
        RÃ©cupÃ¨re toutes les photos publiÃ©es

        Returns:
            Liste de PhotoMetadata
        """
        from backend.core.storage import get_store

        store = get_store()
        with store.get_connection() as conn:
            cursor = conn.cursor()

            cursor.execute("""
                SELECT * FROM photo_metadata
                WHERE published_to_vinted = 1
            """)

            rows = cursor.fetchall()

            photos = []
            for row in rows:
                photo = PhotoMetadata(
                    photo_id=row['photo_id'],
                    user_id=row['user_id'],
                    draft_id=row['draft_id'],
                    tier=StorageTier(row['tier']),
                    original_filename=row['original_filename'],
                    size_bytes=row['size_bytes'],
                    compressed_size_bytes=row['compressed_size_bytes'],
                    upload_date=datetime.fromisoformat(row['upload_date']) if row['upload_date'] else None,
                    last_accessed=datetime.fromisoformat(row['last_accessed']) if row['last_accessed'] else None,
                    published_to_vinted=bool(row['published_to_vinted']),
                    published_date=datetime.fromisoformat(row['published_date']) if row['published_date'] else None,
                    scheduled_deletion=datetime.fromisoformat(row['scheduled_deletion']) if row['scheduled_deletion'] else None
                )
                photos.append(photo)

            return photos

    async def _get_photos_older_than(
        self,
        tier: StorageTier,
        hours: int = None,
        days: int = None
    ) -> List[PhotoMetadata]:
        """
        RÃ©cupÃ¨re photos plus vieilles que X

        Args:
            tier: Tier de stockage
            hours: Nombre d'heures (optionnel)
            days: Nombre de jours (optionnel)

        Returns:
            Liste de PhotoMetadata
        """
        if hours:
            threshold = datetime.utcnow() - timedelta(hours=hours)
        elif days:
            threshold = datetime.utcnow() - timedelta(days=days)
        else:
            return []

        from backend.core.storage import get_store

        store = get_store()
        with store.get_connection() as conn:
            cursor = conn.cursor()

            cursor.execute("""
                SELECT * FROM photo_metadata
                WHERE tier = ? AND upload_date < ?
            """, (tier.value, threshold.isoformat()))

            rows = cursor.fetchall()

            photos = []
            for row in rows:
                photo = PhotoMetadata(
                    photo_id=row['photo_id'],
                    user_id=row['user_id'],
                    draft_id=row['draft_id'],
                    tier=StorageTier(row['tier']),
                    original_filename=row['original_filename'],
                    size_bytes=row['size_bytes'],
                    compressed_size_bytes=row['compressed_size_bytes'],
                    upload_date=datetime.fromisoformat(row['upload_date']) if row['upload_date'] else None,
                    last_accessed=datetime.fromisoformat(row['last_accessed']) if row['last_accessed'] else None,
                    published_to_vinted=bool(row['published_to_vinted']),
                    published_date=datetime.fromisoformat(row['published_date']) if row['published_date'] else None,
                    scheduled_deletion=datetime.fromisoformat(row['scheduled_deletion']) if row['scheduled_deletion'] else None
                )
                photos.append(photo)

            return photos

    async def _get_photos_not_accessed_for(
        self,
        tier: StorageTier,
        days: int
    ) -> List[PhotoMetadata]:
        """
        RÃ©cupÃ¨re photos non accÃ©dÃ©es depuis X jours

        Args:
            tier: Tier de stockage
            days: Nombre de jours

        Returns:
            Liste de PhotoMetadata
        """
        threshold = datetime.utcnow() - timedelta(days=days)

        from backend.core.storage import get_store

        store = get_store()
        with store.get_connection() as conn:
            cursor = conn.cursor()

            cursor.execute("""
                SELECT * FROM photo_metadata
                WHERE tier = ? AND last_accessed < ?
            """, (tier.value, threshold.isoformat()))

            rows = cursor.fetchall()

            photos = []
            for row in rows:
                photo = PhotoMetadata(
                    photo_id=row['photo_id'],
                    user_id=row['user_id'],
                    draft_id=row['draft_id'],
                    tier=StorageTier(row['tier']),
                    original_filename=row['original_filename'],
                    size_bytes=row['size_bytes'],
                    compressed_size_bytes=row['compressed_size_bytes'],
                    upload_date=datetime.fromisoformat(row['upload_date']) if row['upload_date'] else None,
                    last_accessed=datetime.fromisoformat(row['last_accessed']) if row['last_accessed'] else None,
                    published_to_vinted=bool(row['published_to_vinted']),
                    published_date=datetime.fromisoformat(row['published_date']) if row['published_date'] else None,
                    scheduled_deletion=datetime.fromisoformat(row['scheduled_deletion']) if row['scheduled_deletion'] else None
                )
                photos.append(photo)

            return photos
